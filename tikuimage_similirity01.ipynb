{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import requests\n",
    "import io\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import math\n",
    "import pathlib\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Flatten, Conv2D, Conv2DTranspose, LeakyReLU, BatchNormalization, Input, Dense, Reshape, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8 # 每⼀批所处理的图⽚数量\n",
    "img_height = 256 # 图⽚⾼度，单位为像素\n",
    "img_width = 256 # 图⽚宽度，单位为像素\n",
    "\n",
    "channels = 3\n",
    "\n",
    "train_dir = './datasets/tikuimage'\n",
    "\n",
    "TF_SERVING_BASE_URL = 'http://localhost:8501/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54 images belonging to 2 classes.\n",
      "Found 13 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   validation_split=0.2)\n",
    " \n",
    "training_set = train_datagen.flow_from_directory(\n",
    "     train_dir,\n",
    "     target_size = (img_height, img_width),\n",
    "     batch_size = batch_size,\n",
    "     class_mode = 'input',\n",
    "     subset = 'training',\n",
    "     shuffle=True)\n",
    " \n",
    "validation_set = train_datagen.flow_from_directory(\n",
    "     train_dir,\n",
    "     target_size = (img_height, img_width),\n",
    "     batch_size = batch_size,\n",
    "     class_mode = 'input',\n",
    "     subset = 'validation',\n",
    "     shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunxiaohua/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "6/6 [==============================] - 17s 3s/step - loss: 0.2790 - val_loss: 0.8813\n",
      "Epoch 2/3\n",
      "6/6 [==============================] - 15s 2s/step - loss: 0.2253 - val_loss: 0.6009\n",
      "Epoch 3/3\n",
      "6/6 [==============================] - 16s 3s/step - loss: 0.1998 - val_loss: 0.8982\n"
     ]
    }
   ],
   "source": [
    "# Define the autoencoder\n",
    "input_model = Input(shape=(img_height, img_width, channels))\n",
    " \n",
    "# Encoder layers\n",
    "encoder = Conv2D(32, (3,3), padding='same', kernel_initializer='normal')(input_model)\n",
    "encoder = LeakyReLU()(encoder)\n",
    "encoder = BatchNormalization(axis=-1)(encoder)\n",
    " \n",
    "encoder = Conv2D(64, (3,3), padding='same', kernel_initializer='normal')(encoder)\n",
    "encoder = LeakyReLU()(encoder)\n",
    "encoder = BatchNormalization(axis=-1)(encoder)\n",
    " \n",
    "encoder = Conv2D(64, (3,3), padding='same', kernel_initializer='normal')(input_model)\n",
    "encoder = LeakyReLU()(encoder)\n",
    "encoder = BatchNormalization(axis=-1)(encoder)\n",
    " \n",
    "encoder_dim = K.int_shape(encoder)\n",
    "encoder = Flatten()(encoder)\n",
    " \n",
    "# Latent Space\n",
    "latent_space = Dense(16, name='latent_space')(encoder)\n",
    " \n",
    "# Decoder Layers\n",
    "decoder = Dense(np.prod(encoder_dim[1:]))(latent_space)\n",
    "decoder = Reshape((encoder_dim[1], encoder_dim[2], encoder_dim[3]))(decoder)\n",
    " \n",
    "decoder = Conv2DTranspose(64, (3,3), padding='same', kernel_initializer='normal')(decoder)\n",
    "decoder = LeakyReLU()(decoder)\n",
    "decoder = BatchNormalization(axis=-1)(decoder)\n",
    " \n",
    "decoder = Conv2DTranspose(64, (3,3), padding='same', kernel_initializer='normal')(decoder)\n",
    "decoder = LeakyReLU()(decoder)\n",
    "decoder = BatchNormalization(axis=-1)(decoder)\n",
    " \n",
    "decoder = Conv2DTranspose(32, (3,3), padding='same', kernel_initializer='normal')(decoder)\n",
    "decoder = LeakyReLU()(decoder)\n",
    "decoder = BatchNormalization(axis=-1)(decoder)\n",
    " \n",
    "decoder = Conv2DTranspose(3, (3, 3), padding=\"same\")(decoder)\n",
    "output = Activation('sigmoid', name='decoder')(decoder)\n",
    " \n",
    "# Create model object\n",
    "autoencoder = Model(input_model, output, name='autoencoder')\n",
    " \n",
    "# Compile the model\n",
    "autoencoder.compile(loss=\"mse\", optimizer= Adam(learning_rate=1e-3))\n",
    " \n",
    "# Fit the model\n",
    "history = autoencoder.fit_generator(\n",
    "          training_set,\n",
    "          steps_per_epoch=training_set.n // batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=validation_set,\n",
    "          validation_steps=validation_set.n // batch_size,\n",
    "          callbacks = [ModelCheckpoint('models/image_autoencoder_2.h5', \n",
    "                                       monitor='val_loss', \n",
    "                                       verbose=0, \n",
    "                                       save_best_only=True, \n",
    "                                       save_weights_only=False)])\n",
    "                                       \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_model = Model(\n",
    "                      autoencoder.input, \n",
    "                      autoencoder.get_layer('latent_space').output)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-7cf31b600ffc>:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm(range(len(os.listdir('./datasets/tikuimage/new')))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c42bce89e9f64d1a93cf4ec3c69c98d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n",
      "[Errno 2] No such file or directory: './datasets/tikuimage/new/.DS_Store'\n",
      "1\n",
      "[Errno 2] No such file or directory: './datasets/tikuimage/new/1'\n",
      "new\n",
      "[Errno 2] No such file or directory: './datasets/tikuimage/new/new'\n",
      ".ipynb_checkpoints\n",
      "[Errno 2] No such file or directory: './datasets/tikuimage/new/.ipynb_checkpoints'\n",
      "\n",
      "{'indices': [], 'features': array([], dtype=float64)}\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "indices = []\n",
    "\n",
    "#Tqdm 是一个快速，可扩展的Python进度条，可以在 Python 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器 tqdm(iterator)。\n",
    " \n",
    "for i in tqdm(range(len(os.listdir('./datasets/tikuimage/new')))):\n",
    "  try:\n",
    "    img_name = os.listdir('./datasets/tikuimage')[i]\n",
    "    img = load_img('./datasets/tikuimage/new/{}'.format(img_name), \n",
    "                   target_size = (256, 256))\n",
    "    img = img_to_array(img) / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    pred = latent_space_model.predict(img)\n",
    "    pred = np.resize(pred, (16))\n",
    "    X.append(pred)\n",
    "    indices.append(img_name)\n",
    " \n",
    "  except Exception as e:\n",
    "    print(img_name)\n",
    "    print(e)\n",
    "\n",
    "    # Export the embeddings\n",
    "embeddings = {'indices': indices, 'features': np.array(X)}\n",
    "print(embeddings)\n",
    "#pickle.dump(embeddings, open('./image_embeddings.pickle', 'wb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_ds.class_names)\n",
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "model = tf.keras.Sequential([ # 根据需要调整模型结构\n",
    "layers.experimental.preprocessing.Resizing(img_height, img_width),\n",
    "tf.keras.layers.experimental.preprocessing.Rescaling(1. / 255),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes)\n",
    "   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "optimizer='adam',\n",
    "loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "train_ds,\n",
    "validation_data=val_ds,\n",
    "epochs=1\n",
    ")\n",
    "print(model.evaluate(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(\n",
    "model,\n",
    "'./models/image/1/', # ./models为tensorflow-serving的模型根⽬录\n",
    "overwrite=True,\n",
    "include_optimizer=True,\n",
    "save_format=None,\n",
    "signatures=None,\n",
    "options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image_model(test_dir, code, batch_size=10): \n",
    "  imgs = []\n",
    "  codes = []\n",
    "  imgdir = os.path.join(test_dir, str(code)) \n",
    "  for i in pathlib.Path(imgdir).glob('./*.jpg'): \n",
    "    img = PIL.Image.open(i)\n",
    "    pixels = np.array(img)\n",
    "    imgs.append(pixels.tolist()) \n",
    "  for i in range(int(math.ceil(len(imgs)/batch_size))):\n",
    "    req_data = json.dumps({\n",
    "'     inputs': imgs[i*batch_size:(i+1)*batch_size],\n",
    "    }) \n",
    "    #http://localhost:8501/v1/models/fashion_mnist:predict\n",
    "    response = requests.post(TF_SERVING_BASE_URL+'v1/models/image/versions/1:predict', # 根据部署地址填写\n",
    "    data=req_data,\n",
    "    headers={\"content-type\": \"application/json\"})\n",
    "    if response.status_code != 200:\n",
    "      raise RuntimeError('Request tf-serving failed: ' + response.text)\n",
    "    resp_data = json.loads(response.text) \n",
    "    if 'outputs' not in resp_data \\\n",
    "         or type(resp_data['outputs']) is not list:\n",
    "      raise ValueError('Malformed tf-serving response')\n",
    "    codes.extend(np.argmax(resp_data['outputs'], axis=1).tolist())\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = test_image_model(val_ds, 0)\n",
    "print('类别0的准确率', 1 - round(np.sum(codes)/len(codes),4))\n",
    "codes = test_image_model(val_ds, 1)\n",
    "print('类别1的准确率', round(np.sum(codes)/len(codes),4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
