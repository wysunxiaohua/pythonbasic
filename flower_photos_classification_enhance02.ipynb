{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8 # 每⼀批所处理的图⽚数量\n",
    "img_height = 256 # 图⽚⾼度，单位为像素\n",
    "img_width = 256 # 图⽚宽度，单位为像素\n",
    "\n",
    "train_dir = './datasets/flower_photos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 2936 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "train_dir,\n",
    "validation_split=0.2, # 设定验证集⽐例\n",
    "subset=\"training\",\n",
    "seed=123,\n",
    "image_size=(img_height, img_width),\n",
    "batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 734 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "train_dir,\n",
    "validation_split=0.2, # 设定验证集⽐例\n",
    "subset=\"validation\",\n",
    "seed=123,\n",
    "image_size=(img_height, img_width),\n",
    "batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
      "(8, 256, 256, 3)\n",
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "print(train_ds.class_names)\n",
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.shuffle(buffer_size=1000).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_dict = {\n",
    "    'RandomFlip': tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    'RandomRotation': tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    'RandomContrast': tf.keras.layers.experimental.preprocessing.RandomContrast(0.2),\n",
    "    'RandomZoom': tf.keras.layers.experimental.preprocessing.RandomZoom(height_factor=0.1, width_factor=0.1),\n",
    "    'RandomTranslation': tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "    'RandomCrop': tf.keras.layers.experimental.preprocessing.RandomCrop(img_height, img_width),\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Number of layers in the base model:  154\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.truediv (TFOpLambda) (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_224 (Functi (None, 8, 8, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 6405      \n",
      "=================================================================\n",
      "Total params: 2,264,389\n",
      "Trainable params: 1,867,845\n",
      "Non-trainable params: 396,544\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "num_classes = 5\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    augmentation_dict['RandomTranslation'],\n",
    "])\n",
    "\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(img_height,img_width,3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_model.trainable = True\n",
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=(img_height,img_width,3))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(num_classes)(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.load_weights('./models/image/mobilenet_v2.h5',by_name=True)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "optimizer='adam',\n",
    "loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "metrics=['accuracy'])\n",
    "\n",
    "tf.keras.backend.set_value(model.optimizer.learning_rate, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/mobilenetv2_\" + str('RandomTranslation') + '_' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer = tf.summary.create_file_writer(log_dir + '/lr')\n",
    "file_writer.set_as_default()\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5,\n",
    "                                              restore_best_weights=True)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallback(ReduceLROnPlateau):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = backend.get_value(self.model.optimizer.lr)\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            logging.warning('Learning rate reduction is conditioned on metric `%s` '\n",
    "                            'which is not available. Available metrics are: %s',\n",
    "                            self.monitor, ','.join(list(logs.keys())))\n",
    "\n",
    "        else:\n",
    "            if self.in_cooldown():\n",
    "                self.cooldown_counter -= 1\n",
    "                self.wait = 0\n",
    "\n",
    "            if self.monitor_op(current, self.best):\n",
    "                self.best = current\n",
    "                self.wait = 0\n",
    "            elif not self.in_cooldown():\n",
    "                self.wait += 1\n",
    "                if self.wait >= self.patience:\n",
    "                    old_lr = backend.get_value(self.model.optimizer.lr)\n",
    "                    if old_lr > np.float32(self.min_lr):\n",
    "                        new_lr = old_lr * self.factor\n",
    "                        new_lr = max(new_lr, self.min_lr)\n",
    "                        tf.summary.scalar('learning rate', data=new_lr, step=epoch)\n",
    "                        backend.set_value(self.model.optimizer.lr, new_lr)\n",
    "                        if self.verbose > 0:\n",
    "                            print('\\nEpoch %05d: ReduceLROnPlateau reducing learning '\n",
    "                                  'rate to %s.' % (epoch + 1, new_lr))\n",
    "                        self.cooldown_counter = self.cooldown\n",
    "                        self.wait = 0\n",
    "\n",
    "\n",
    "reduce_lr = MyCallback(monitor='val_loss', factor=0.2,\n",
    "                       patience=3, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunxiaohua/opt/anaconda3/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "367/367 - 114s - loss: 0.5619 - accuracy: 0.7851 - val_loss: 0.4114 - val_accuracy: 0.8556\n",
      "Epoch 2/5\n",
      "367/367 - 109s - loss: 0.2966 - accuracy: 0.8971 - val_loss: 0.3436 - val_accuracy: 0.8910\n",
      "Epoch 3/5\n",
      "367/367 - 110s - loss: 0.2199 - accuracy: 0.9230 - val_loss: 0.3629 - val_accuracy: 0.8937\n",
      "Epoch 4/5\n",
      "367/367 - 112s - loss: 0.1867 - accuracy: 0.9343 - val_loss: 0.3958 - val_accuracy: 0.8842\n",
      "Epoch 5/5\n",
      "367/367 - 122s - loss: 0.1633 - accuracy: 0.9407 - val_loss: 0.2583 - val_accuracy: 0.9196\n",
      "92/92 [==============================] - 17s 184ms/step - loss: 0.2583 - accuracy: 0.9196\n",
      "[0.25834590196609497, 0.919618546962738]\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "train_ds,\n",
    "validation_data=val_ds,\n",
    "callbacks = [reduce_lr, early_stop, tensorboard_callback],\n",
    "epochs=5,\n",
    "verbose=2\n",
    ")\n",
    "print(model.evaluate(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/image/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunxiaohua/opt/anaconda3/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(\n",
    "model,\n",
    "'./models/image/1/', # ./models为tensorflow-serving的模型根⽬录\n",
    "overwrite=True,\n",
    "include_optimizer=True,\n",
    "save_format=None,\n",
    "signatures=None,\n",
    "options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
